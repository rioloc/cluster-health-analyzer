# LightSpeed Evaluation Framework - Focused Query Test Data
# Test queries for specific incident analysis scenarios

- conversation_group_id: "focused_incident_analysis"
  description: "Focused evaluation queries for multiple incidents with overlapping alerts, incident explanations, application troubleshooting, and critical incident listing"

  conversation_metrics: []
  conversation_metrics_metadata: {}

  turns:
    # Test Case 1: List only critical firing incidents
    - turn_id: "list_critical_firing_incidents"
      query: "What are the current firing alerts in the cluster?"
      response: null
      contexts:
        - "Critical severity incidents represent the most serious cluster problems."
        - "Incident a96081f6-542e-4a60-b3bb-6bb7d5b2e169 is a critical incident affecting control plane."
      expected_response: |
        The cluster currently has 3 active incidents requiring attention:
        Incident a96081f6-542e-4a60-b3bb-6bb7d5b2e169: Critical severity incident impacting "my-app" and "storage" components with the following alerts:
            KubePersistentVolumeErrors (warning) in openshift-storage
            KubePodNotReady (warning) in my-app These alerts suggest persistent volume issues affecting pod availability.
        Incident 9ce79082-3803-4ba0-a130-97994fd7966b: Info severity incident concerning cluster version management. Alert:
            UpdateAvailable (info, silenced) in openshift-cluster-version This shows a cluster update is pending but silenced.
        Incident 95eed194-2778-467d-8fd1-c2128b164151: Warning severity incident related to monitoring configuration. Alert:
            AlertmanagerReceiversNotConfigured (warning) in openshift-monitoring This reveals incomplete Alertmanager receiver configuration.

      expected_tool_calls:
        - - tool_name: get_incidents
            arguments:
              max_age_hours: "\\d+"

      turn_metrics:
        - "custom:answer_correctness"

      turn_metrics_metadata:
        "custom:answer_correctness":
          threshold: 0.70

    # Test Case 2: Why my-app is down
    - turn_id: "why_my_app_down"
      query: "Why is my-app down?"
      response: null
      contexts:
        - "Application health in my-app namespace is affected by KubePodNotReady alert."
        - "Pod readiness issues are often symptoms of underlying infrastructure problems."
        - "The my-app namespace issues are connected to the broader control plane failures."
      expected_response: |
        The "my-app" application is experiencing downtime caused by critical incident a96081f6-542e-4a60-b3bb-6bb7d5b2e169, which determines pod readiness failures and storage volume problems. The incident features a "KubePodNotReady" warning within the "my-app" namespace alongside "KubePersistentVolumeErrors" occurring in the "openshift-storage" namespace, demonstrating that storage infrastructure problems are preventing your application pods from achieving ready status.
        Additional unrelated incidents exist including a pending cluster version update and monitoring configuration issues.

      expected_tool_calls:
        - - tool_name: get_incidents
            arguments:
              max_age_hours: "\\d+"

      turn_metrics:
        - "ragas:response_relevancy"
        - "custom:answer_correctness"

      turn_metrics_metadata:
        "ragas:response_relevancy":
          threshold: 0.50
        "custom:answer_correctness":
          threshold: 0.65

    # Test Case 3: Explain incident
    - turn_id: "explain_incident_details"
      query: "Explain incident a96081f6-542e-4a60-b3bb-6bb7d5b2e169"
      response: null
      contexts:
        - "Incident a96081f6-542e-4a60-b3bb-6bb7d5b2e169 is a critical incident with multiple alerts."
        - "This incident contains etcd, scheduler, controller manager, and storage alerts."
        - "The incident started with etcd problems and cascaded to other components."
      expected_response: |
        Incident a96081f6-542e-4a60-b3bb-6bb7d5b2e169 represents a critical-severity event encompassing "my-app" pod availability problems and storage subsystem failures. The incident comprises two active alerts: "KubePodNotReady" within the "my-app" namespace and "KubePersistentVolumeErrors" originating from "openshift-storage." This configuration suggests that application pods cannot reach operational readiness, presumably due to fundamental storage infrastructure issues impacting persistent volume functionality. The incident remains active and demands comprehensive analysis of both pod lifecycle management and storage error conditions to restore application services.

      expected_tool_calls:
        - - tool_name: get_incidents
            arguments:
              max_age_hours: "\\d+"

      turn_metrics:
        - "ragas:response_relevancy"
        - "custom:answer_correctness"

      turn_metrics_metadata:
        "custom:answer_correctness":
          threshold: 0.80

    # Test Case 4: Why this alert is happening
    - turn_id: "why_alert_happening"
      query: "Why is the etcdHighNumberOfFailedProposals alert happening?"
      response: null
      contexts:
        - "etcdHighNumberOfFailedProposals indicates consensus mechanism failures in etcd."
        - "This alert is part of incident a96081f6-542e-4a60-b3bb-6bb7d5b2e169."
        - "etcd proposal failures can be caused by network issues, disk performance, or cluster membership problems."
      expected_response: |
        The etcdHighNumberOfFailedProposals alert signifies an elevated rate of failed consensus proposals within the etcd cluster. This condition typically manifests due to several potential factors:
        Networking disruptions that impair inter-member communication within the etcd cluster.
        Resource limitations including CPU starvation, memory pressure, or disk I/O performance degradation on etcd nodes.
        etcd member unavailability or failures that prevent achieving the required consensus quorum.
        Misconfigurations or software defects leading to systematic proposal rejections during the consensus process.


      expected_tool_calls:
        - - tool_name: get_incidents
            arguments:
              max_age_hours: "\\d+"

      turn_metrics:
        - "ragas:response_relevancy"
        - "custom:answer_correctness"

      turn_metrics_metadata:
        "ragas:response_relevancy":
          threshold: 0.75
        "custom:answer_correctness":
          threshold: 0.80
